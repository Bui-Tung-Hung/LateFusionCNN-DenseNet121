{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qxsbZTTqszrw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ef391ae-9ba7-4431-96c5-d57da8040f5f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eJvuo5wTsiAF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nth3GK5XpiTv"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "import keras\n",
        "from keras.applications import DenseNet121\n",
        "from keras.models import Model, Sequential\n",
        "from keras import layers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.metrics import AUC\n",
        "# from keras.metrics import f1_score\n",
        "from keras.metrics import Precision\n",
        "from sklearn.metrics import accuracy_score, recall_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import F1Score, AUC, Precision, Recall\n",
        "from tensorflow.keras.layers import MaxPooling2D, Dropout\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DenseNet121\n"
      ],
      "metadata": {
        "id": "D8De27i4sjfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "\n",
        "def get_mel_spectrogram(file_directory, sr=22050, desired_shape=(244, 244, 3)):\n",
        "    \"\"\"\n",
        "    Get mel-spectrogram (db) with desired shape\n",
        "    Input: file_directory: str, sr: int, desired_shape: tuple\n",
        "    Output: mel_spec: numpy array\n",
        "    \"\"\"\n",
        "    src, sc = librosa.load(file_directory, sr=22050)\n",
        "    mel_gram = librosa.feature.melspectrogram(y=src, sr=22050)\n",
        "\n",
        "    # Convert to decibels\n",
        "    mel_spec_db = librosa.power_to_db(mel_gram, ref=np.max)\n",
        "\n",
        "    # Resize to desired shape\n",
        "    mel_spec_resized = resize(mel_spec_db, desired_shape)\n",
        "\n",
        "    return mel_spec_resized\n",
        "\n",
        "def process_audio_files(audio_dir):\n",
        "    ''' Process audio files in the specified directory and return log-mel spectrograms and labels.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    audio_dir: str\n",
        "        Path to the directory containing audio files.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    tuple\n",
        "        A tuple containing a list of log-mel spectrograms and corresponding labels.\n",
        "    '''\n",
        "\n",
        "    # List to store log-mel spectrograms and corresponding labels\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    # Iterate over the subdirectories (genres)\n",
        "    for genre_folder in os.listdir(audio_dir):\n",
        "        genre_path = os.path.join(audio_dir, genre_folder)\n",
        "        if os.path.isdir(genre_path):  # Check if it's a directory\n",
        "            # Iterate over all audio files in the genre directory\n",
        "            for filename in os.listdir(genre_path):\n",
        "                if filename.endswith('.wav'):  # Assuming all audio files are in .wav format\n",
        "                    file_path = os.path.join(genre_path, filename)\n",
        "\n",
        "                    # Compute log-mel spectrogram for the current audio file\n",
        "                    log_mel_spectrogram = get_mel_spectrogram(file_path)\n",
        "\n",
        "                    # Append log-mel spectrogram to data list\n",
        "                    data.append(log_mel_spectrogram)\n",
        "\n",
        "                    # Append label to labels list (genre folder name)\n",
        "                    labels.append(genre_folder)\n",
        "\n",
        "    return data, labels\n",
        "\n",
        "# Directory containing audio files\n",
        "audio_dir = '/content/drive/MyDrive/Music_Project/music_data/VNTM3'\n",
        "\n",
        "# Process audio files and retrieve log-mel spectrograms and labels\n",
        "data, labels = process_audio_files(audio_dir)\n"
      ],
      "metadata": {
        "id": "1f9oA0qsIBUb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def process_audio_files(audio_dir, desired_shape=(244, 244, 3)):\n",
        "#     ''' Process precomputed log mel spectrogram PNG files in the specified directory and return them along with labels.\n",
        "\n",
        "#     Parameters:\n",
        "#     ----------\n",
        "#     audio_dir: str\n",
        "#         Path to the directory containing precomputed log mel spectrogram PNG files.\n",
        "#     desired_shape: tuple\n",
        "#         Desired shape for the log mel spectrograms.\n",
        "\n",
        "#     Returns:\n",
        "#     -------\n",
        "#     tuple\n",
        "#         A tuple containing a list of log mel spectrograms and corresponding labels.\n",
        "#     '''\n",
        "\n",
        "#     # List to store log mel spectrograms and corresponding labels\n",
        "#     data = []\n",
        "#     labels = []\n",
        "\n",
        "#     # Iterate over the subdirectories (genres)\n",
        "#     for genre_folder in os.listdir(audio_dir):\n",
        "#         genre_path = os.path.join(audio_dir, genre_folder)\n",
        "#         if os.path.isdir(genre_path):  # Check if it's a directory\n",
        "#             # Iterate over all precomputed log mel spectrogram PNG files in the genre directory\n",
        "#             for filename in os.listdir(genre_path):\n",
        "#                  # Assuming all precomputed log mel spectrogram files are in .png format\n",
        "#                   file_path = os.path.join(genre_path, filename)\n",
        "\n",
        "#                   # Load precomputed log mel spectrogram PNG file\n",
        "#                   log_mel_spectrogram = cv2.imread(file_path)\n",
        "\n",
        "#                   # Convert image to numpy array and normalize\n",
        "#                   log_mel_spectrogram_array = log_mel_spectrogram / 255.0\n",
        "\n",
        "#                   # Resize the array to the desired shape\n",
        "#                   log_mel_spectrogram_array_resized = cv2.resize(log_mel_spectrogram_array, (desired_shape[1], desired_shape[0]))\n",
        "\n",
        "#                   # Append log mel spectrogram to data list\n",
        "#                   data.append(log_mel_spectrogram_array_resized)\n",
        "\n",
        "#                   # Append label to labels list (genre folder name)\n",
        "#                   labels.append(genre_folder)\n",
        "#     return data, labels\n",
        "\n",
        "\n",
        "# audio_dir = r'/content/drive/MyDrive/Music_Project/music_data/mel_images'\n",
        "# data, labels = process_audio_files(audio_dir)\n"
      ],
      "metadata": {
        "id": "58q5aexXptnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and combined validation-evaluation set\n",
        "x_train, x_combined, y_train, y_combined = train_test_split(data, labels, test_size=0.2, random_state=42, shuffle=True, stratify =labels)\n",
        "\n",
        "# Split combined set into validation and evaluation sets\n",
        "x_validate, x_test, y_validate, y_test = train_test_split(x_combined, y_combined, test_size=0.5, random_state=42, shuffle=True, stratify =y_combined)\n"
      ],
      "metadata": {
        "id": "PucYcIpmpyiA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "label_binarizer = LabelBinarizer()\n",
        "# Fit and transform training labels\n",
        "y_train_one_hot = label_binarizer.fit_transform(y_train)\n",
        "y_validate_one_hot = label_binarizer.transform(y_validate)\n",
        "y_test_one_hot = label_binarizer.transform(y_test)\n",
        "y_test_encoded = label_encoder.fit_transform(y_test)\n",
        "# Fit and transform evaluation labels\n",
        "y_test_encoded = label_encoder.fit_transform(y_test)\n",
        "y_test_one_hot = label_binarizer.transform(y_test)"
      ],
      "metadata": {
        "id": "nt8EWnLyp0ig"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x_test = np.array(x_test, dtype=np.float32)\n",
        "# x_train = np.array(x_train, dtype = np.float32)\n",
        "# x_validate = np.array(x_validate, dtype=np.float32)"
      ],
      "metadata": {
        "id": "oG0AePpJp37Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array(x_test, dtype=np.float32)\n",
        "X_train = np.array(x_train, dtype = np.float32)\n",
        "X_validate = np.array(x_validate, dtype=np.float32)"
      ],
      "metadata": {
        "id": "oo2CfyioRcxA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = DenseNet121(weights='imagenet',\n",
        "                         include_top=False,\n",
        "                         input_shape=(244,244,3))\n",
        "\n",
        "early = EarlyStopping(monitor='val_loss',\n",
        "                      min_delta=0.0001,\n",
        "                      mode='min',\n",
        "                      verbose=0,\n",
        "                      patience=5,\n",
        "                      baseline= None,\n",
        "                      restore_best_weights= True)\n",
        "\n",
        "top_model = Sequential([\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model = Model(inputs=base_model.input,\n",
        "              outputs=top_model(base_model.output))\n",
        "\n",
        "# Freeze base layers to prevent retraining\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "#model.summary()\n",
        "\n",
        "model.fit(X_train, y_train_one_hot,\n",
        "          epochs=100,\n",
        "          validation_data=(X_validate, y_validate_one_hot),\n",
        "          callbacks=[early],\n",
        "          shuffle=True,\n",
        "          verbose=1,\n",
        "          batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn5J1ZdWqBNg",
        "outputId": "f8980baf-4af2-473a-9eb9-5c350e5b68d9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29084464/29084464 [==============================] - 1s 0us/step\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 20s 148ms/step - loss: 1.4075 - accuracy: 0.5678 - val_loss: 0.5092 - val_accuracy: 0.8480\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 3s 50ms/step - loss: 0.6149 - accuracy: 0.7774 - val_loss: 0.4036 - val_accuracy: 0.8600\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 3s 51ms/step - loss: 0.4989 - accuracy: 0.8129 - val_loss: 0.3446 - val_accuracy: 0.8600\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 3s 51ms/step - loss: 0.4215 - accuracy: 0.8484 - val_loss: 0.2680 - val_accuracy: 0.9200\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 3s 52ms/step - loss: 0.3729 - accuracy: 0.8639 - val_loss: 0.2451 - val_accuracy: 0.9200\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 3s 50ms/step - loss: 0.3673 - accuracy: 0.8654 - val_loss: 0.2556 - val_accuracy: 0.9200\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 3s 52ms/step - loss: 0.3161 - accuracy: 0.8829 - val_loss: 0.2244 - val_accuracy: 0.9040\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.2963 - accuracy: 0.8934 - val_loss: 0.2426 - val_accuracy: 0.8960\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 3s 50ms/step - loss: 0.2826 - accuracy: 0.8954 - val_loss: 0.2160 - val_accuracy: 0.9160\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 3s 52ms/step - loss: 0.2834 - accuracy: 0.9075 - val_loss: 0.1875 - val_accuracy: 0.9280\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.2616 - accuracy: 0.9010 - val_loss: 0.2381 - val_accuracy: 0.8920\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 3s 51ms/step - loss: 0.2521 - accuracy: 0.9090 - val_loss: 0.1728 - val_accuracy: 0.9400\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 3s 51ms/step - loss: 0.2236 - accuracy: 0.9230 - val_loss: 0.1582 - val_accuracy: 0.9240\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.2405 - accuracy: 0.9115 - val_loss: 0.1870 - val_accuracy: 0.9400\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.2480 - accuracy: 0.9040 - val_loss: 0.1714 - val_accuracy: 0.9360\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 3s 51ms/step - loss: 0.1942 - accuracy: 0.9370 - val_loss: 0.1568 - val_accuracy: 0.9480\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.1939 - accuracy: 0.9320 - val_loss: 0.1607 - val_accuracy: 0.9400\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 3s 51ms/step - loss: 0.2054 - accuracy: 0.9285 - val_loss: 0.1151 - val_accuracy: 0.9600\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.1722 - accuracy: 0.9365 - val_loss: 0.1354 - val_accuracy: 0.9400\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.1904 - accuracy: 0.9300 - val_loss: 0.1425 - val_accuracy: 0.9360\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.2175 - accuracy: 0.9185 - val_loss: 0.1435 - val_accuracy: 0.9320\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - 3s 49ms/step - loss: 0.1699 - accuracy: 0.9375 - val_loss: 0.1508 - val_accuracy: 0.9280\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - 3s 52ms/step - loss: 0.1700 - accuracy: 0.9385 - val_loss: 0.1594 - val_accuracy: 0.9400\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cf7ac745fc0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict = model.predict(X_test)\n",
        "\n",
        "\n",
        "# Convert one-hot encoded predicted labels back to original labels\n",
        "test_predictions_labels = label_encoder.inverse_transform(np.argmax(predict, axis=1))\n",
        "# Convert one-hot encoded predicted labels back to original labels\n",
        "test_predictions_labels_encoded = label_encoder.inverse_transform(np.argmax(predict, axis=1))\n",
        "\n",
        "\n",
        "# Calculate AUC_ROC\n",
        "auc_roc = AUC()\n",
        "auc_roc.update_state(y_test_one_hot, predict)\n",
        "print(\"AUC ROC:\", auc_roc.result().numpy())\n",
        "\n",
        "# Calculate F1 Score\n",
        "f1 = F1Score()\n",
        "f1.update_state(y_test_one_hot, predict)\n",
        "print(\"F1 Score:\", np.mean(f1.result().numpy()))\n",
        "\n",
        "# Calculate Precision\n",
        "pre = Precision()\n",
        "pre.update_state(y_test_one_hot, predict)\n",
        "print(\"Precision Score\", pre.result().numpy())\n",
        "\n",
        "# Accuracy Score\n",
        "acc = accuracy_score(y_test, test_predictions_labels)\n",
        "print(\"Accuracy Score\", acc)\n",
        "\n",
        "print(\"Recall Score:\", recall_score(y_test_encoded, np.argmax(predict, axis=1), average='macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At6OBO3lqGdu",
        "outputId": "97216a4f-0aed-46bb-80b1-31c84938c399"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 2s 38ms/step\n",
            "AUC ROC: 0.998442\n",
            "F1 Score: 0.9605526\n",
            "Precision Score 0.9676113\n",
            "Accuracy Score 0.96\n",
            "Recall Score: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions_labels_encoded_list = test_predictions_labels_encoded.tolist()"
      ],
      "metadata": {
        "id": "KNUopqdoyuHV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print results\n",
        "print(\"Sample\\t\\tTrue Label\\tPredicted Label\")\n",
        "print(\"-\" * 40)\n",
        "for i in range(len(y_test)):\n",
        "    print(f\"{i+1}\\t\\t{y_test[i]}\\t\\t{test_predictions_labels_encoded_list[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c909kbK5qSkO",
        "outputId": "b50d62f2-aaec-4bf0-93db-bf671b16c45b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample\t\tTrue Label\tPredicted Label\n",
            "----------------------------------------\n",
            "1\t\tcheo\t\tcheo\n",
            "2\t\tcailuong\t\tcailuong\n",
            "3\t\tcheo\t\tcheo\n",
            "4\t\tchauvan\t\tchauvan\n",
            "5\t\tcatru\t\tcatru\n",
            "6\t\thatxam\t\thatxam\n",
            "7\t\tcheo\t\tcheo\n",
            "8\t\tcailuong\t\tcailuong\n",
            "9\t\thatxam\t\thatxam\n",
            "10\t\tcailuong\t\tcailuong\n",
            "11\t\tcailuong\t\tcailuong\n",
            "12\t\thatxam\t\thatxam\n",
            "13\t\tchauvan\t\tchauvan\n",
            "14\t\tcheo\t\tcheo\n",
            "15\t\tcheo\t\tcheo\n",
            "16\t\tcatru\t\tcatru\n",
            "17\t\tcheo\t\tcheo\n",
            "18\t\thatxam\t\thatxam\n",
            "19\t\thatxam\t\tchauvan\n",
            "20\t\tchauvan\t\tchauvan\n",
            "21\t\tcatru\t\tcatru\n",
            "22\t\tchauvan\t\tchauvan\n",
            "23\t\thatxam\t\thatxam\n",
            "24\t\thatxam\t\thatxam\n",
            "25\t\thatxam\t\thatxam\n",
            "26\t\tchauvan\t\tchauvan\n",
            "27\t\tcatru\t\tcatru\n",
            "28\t\tchauvan\t\tchauvan\n",
            "29\t\tcheo\t\thatxam\n",
            "30\t\tcheo\t\tcheo\n",
            "31\t\thatxam\t\thatxam\n",
            "32\t\tchauvan\t\tchauvan\n",
            "33\t\thatxam\t\thatxam\n",
            "34\t\thatxam\t\tchauvan\n",
            "35\t\tcailuong\t\tcailuong\n",
            "36\t\tcailuong\t\tcailuong\n",
            "37\t\tcatru\t\tcatru\n",
            "38\t\tchauvan\t\tchauvan\n",
            "39\t\tcheo\t\tcheo\n",
            "40\t\tchauvan\t\tchauvan\n",
            "41\t\tcatru\t\tcatru\n",
            "42\t\thatxam\t\thatxam\n",
            "43\t\tcheo\t\tcheo\n",
            "44\t\tcheo\t\tcheo\n",
            "45\t\tchauvan\t\tchauvan\n",
            "46\t\thatxam\t\tchauvan\n",
            "47\t\thatxam\t\thatxam\n",
            "48\t\thatxam\t\thatxam\n",
            "49\t\tcheo\t\tcheo\n",
            "50\t\tcailuong\t\tcailuong\n",
            "51\t\tchauvan\t\tchauvan\n",
            "52\t\tcailuong\t\tcailuong\n",
            "53\t\tcailuong\t\tcailuong\n",
            "54\t\tchauvan\t\tchauvan\n",
            "55\t\tcatru\t\tcatru\n",
            "56\t\thatxam\t\thatxam\n",
            "57\t\tchauvan\t\tchauvan\n",
            "58\t\tcailuong\t\tcailuong\n",
            "59\t\tcatru\t\tcatru\n",
            "60\t\tcailuong\t\tcailuong\n",
            "61\t\tcheo\t\tcheo\n",
            "62\t\tcheo\t\tcheo\n",
            "63\t\tcatru\t\tcatru\n",
            "64\t\tcailuong\t\tcailuong\n",
            "65\t\tcatru\t\thatxam\n",
            "66\t\tcailuong\t\thatxam\n",
            "67\t\tchauvan\t\tchauvan\n",
            "68\t\tcatru\t\tcatru\n",
            "69\t\tcailuong\t\tcailuong\n",
            "70\t\tcatru\t\tcatru\n",
            "71\t\tcatru\t\tcatru\n",
            "72\t\tcheo\t\tcheo\n",
            "73\t\tcheo\t\tcheo\n",
            "74\t\thatxam\t\thatxam\n",
            "75\t\tcailuong\t\thatxam\n",
            "76\t\thatxam\t\thatxam\n",
            "77\t\thatxam\t\thatxam\n",
            "78\t\tchauvan\t\tchauvan\n",
            "79\t\thatxam\t\thatxam\n",
            "80\t\tchauvan\t\tchauvan\n",
            "81\t\tchauvan\t\tchauvan\n",
            "82\t\thatxam\t\thatxam\n",
            "83\t\thatxam\t\thatxam\n",
            "84\t\tcailuong\t\thatxam\n",
            "85\t\tcailuong\t\tcailuong\n",
            "86\t\tcatru\t\tcatru\n",
            "87\t\tcailuong\t\tcailuong\n",
            "88\t\tchauvan\t\tchauvan\n",
            "89\t\tcheo\t\tcheo\n",
            "90\t\tchauvan\t\tchauvan\n",
            "91\t\tchauvan\t\tchauvan\n",
            "92\t\tcatru\t\tcatru\n",
            "93\t\tcailuong\t\tcailuong\n",
            "94\t\tcatru\t\thatxam\n",
            "95\t\thatxam\t\thatxam\n",
            "96\t\tcheo\t\tcheo\n",
            "97\t\tcailuong\t\tcailuong\n",
            "98\t\thatxam\t\thatxam\n",
            "99\t\tcheo\t\tcheo\n",
            "100\t\tcailuong\t\tcailuong\n",
            "101\t\tcheo\t\tcheo\n",
            "102\t\tcatru\t\tcatru\n",
            "103\t\thatxam\t\thatxam\n",
            "104\t\tcheo\t\tcheo\n",
            "105\t\thatxam\t\thatxam\n",
            "106\t\thatxam\t\thatxam\n",
            "107\t\tcheo\t\tcheo\n",
            "108\t\tcheo\t\tcheo\n",
            "109\t\tchauvan\t\tchauvan\n",
            "110\t\tcatru\t\tcatru\n",
            "111\t\tcatru\t\tcatru\n",
            "112\t\tcailuong\t\tcailuong\n",
            "113\t\tchauvan\t\tchauvan\n",
            "114\t\thatxam\t\thatxam\n",
            "115\t\tcailuong\t\tcailuong\n",
            "116\t\tchauvan\t\tchauvan\n",
            "117\t\tchauvan\t\tchauvan\n",
            "118\t\tcheo\t\tcheo\n",
            "119\t\tchauvan\t\tchauvan\n",
            "120\t\tcailuong\t\tcailuong\n",
            "121\t\tcheo\t\tcheo\n",
            "122\t\thatxam\t\thatxam\n",
            "123\t\tcailuong\t\tcailuong\n",
            "124\t\tcheo\t\tcheo\n",
            "125\t\tchauvan\t\tchauvan\n",
            "126\t\tcatru\t\tcatru\n",
            "127\t\tcheo\t\tcheo\n",
            "128\t\thatxam\t\thatxam\n",
            "129\t\tchauvan\t\tchauvan\n",
            "130\t\tchauvan\t\tchauvan\n",
            "131\t\tcheo\t\tcheo\n",
            "132\t\tcailuong\t\tcailuong\n",
            "133\t\tcailuong\t\tcailuong\n",
            "134\t\tcheo\t\tcheo\n",
            "135\t\tchauvan\t\tchauvan\n",
            "136\t\tcheo\t\tcheo\n",
            "137\t\tcatru\t\tcatru\n",
            "138\t\tchauvan\t\tchauvan\n",
            "139\t\tcheo\t\tcheo\n",
            "140\t\tcheo\t\tcheo\n",
            "141\t\tcailuong\t\tcailuong\n",
            "142\t\tcheo\t\tcheo\n",
            "143\t\thatxam\t\thatxam\n",
            "144\t\tcheo\t\tcheo\n",
            "145\t\tcailuong\t\tcailuong\n",
            "146\t\tcatru\t\tcatru\n",
            "147\t\tchauvan\t\tchauvan\n",
            "148\t\tcatru\t\tcatru\n",
            "149\t\tcatru\t\tcatru\n",
            "150\t\tchauvan\t\tchauvan\n",
            "151\t\thatxam\t\thatxam\n",
            "152\t\tcailuong\t\tcailuong\n",
            "153\t\tcatru\t\tcatru\n",
            "154\t\tcailuong\t\tcailuong\n",
            "155\t\tcatru\t\tcatru\n",
            "156\t\tcheo\t\tcheo\n",
            "157\t\tcailuong\t\tcailuong\n",
            "158\t\tcatru\t\tcatru\n",
            "159\t\thatxam\t\thatxam\n",
            "160\t\thatxam\t\thatxam\n",
            "161\t\tcailuong\t\tcailuong\n",
            "162\t\tcatru\t\tcatru\n",
            "163\t\tchauvan\t\tchauvan\n",
            "164\t\tcailuong\t\tcailuong\n",
            "165\t\tcheo\t\tcheo\n",
            "166\t\tcatru\t\tcatru\n",
            "167\t\tcailuong\t\tcailuong\n",
            "168\t\tcailuong\t\tcailuong\n",
            "169\t\tchauvan\t\tchauvan\n",
            "170\t\thatxam\t\thatxam\n",
            "171\t\tchauvan\t\tchauvan\n",
            "172\t\tcatru\t\tcatru\n",
            "173\t\tcheo\t\tcheo\n",
            "174\t\tcatru\t\tcatru\n",
            "175\t\tcheo\t\tcheo\n",
            "176\t\tcatru\t\tcatru\n",
            "177\t\tcailuong\t\tcailuong\n",
            "178\t\tcheo\t\tcheo\n",
            "179\t\tchauvan\t\tchauvan\n",
            "180\t\thatxam\t\thatxam\n",
            "181\t\tcailuong\t\tcailuong\n",
            "182\t\tchauvan\t\tchauvan\n",
            "183\t\thatxam\t\thatxam\n",
            "184\t\tcatru\t\tcatru\n",
            "185\t\tcatru\t\tcatru\n",
            "186\t\tcheo\t\tcheo\n",
            "187\t\thatxam\t\thatxam\n",
            "188\t\tchauvan\t\tchauvan\n",
            "189\t\tchauvan\t\tchauvan\n",
            "190\t\tcailuong\t\tcailuong\n",
            "191\t\tchauvan\t\tchauvan\n",
            "192\t\tcatru\t\tcatru\n",
            "193\t\tcailuong\t\tcailuong\n",
            "194\t\tcailuong\t\tcailuong\n",
            "195\t\tcatru\t\tcatru\n",
            "196\t\tcatru\t\tcatru\n",
            "197\t\tcailuong\t\tcailuong\n",
            "198\t\tcatru\t\tcatru\n",
            "199\t\thatxam\t\thatxam\n",
            "200\t\tcheo\t\tcheo\n",
            "201\t\tchauvan\t\tchauvan\n",
            "202\t\tchauvan\t\tchauvan\n",
            "203\t\tcailuong\t\tcailuong\n",
            "204\t\thatxam\t\thatxam\n",
            "205\t\tcatru\t\tcatru\n",
            "206\t\tcatru\t\tcatru\n",
            "207\t\tchauvan\t\tchauvan\n",
            "208\t\thatxam\t\thatxam\n",
            "209\t\thatxam\t\thatxam\n",
            "210\t\thatxam\t\thatxam\n",
            "211\t\tcatru\t\tcatru\n",
            "212\t\tcheo\t\tcheo\n",
            "213\t\thatxam\t\thatxam\n",
            "214\t\tcatru\t\tcatru\n",
            "215\t\tcatru\t\tcatru\n",
            "216\t\tcailuong\t\tcailuong\n",
            "217\t\tcatru\t\tcatru\n",
            "218\t\tcatru\t\tcatru\n",
            "219\t\thatxam\t\thatxam\n",
            "220\t\tcailuong\t\tcailuong\n",
            "221\t\tcheo\t\tcheo\n",
            "222\t\tcheo\t\tcheo\n",
            "223\t\tchauvan\t\tchauvan\n",
            "224\t\tcheo\t\tcheo\n",
            "225\t\tcatru\t\tcatru\n",
            "226\t\tcatru\t\tcatru\n",
            "227\t\tchauvan\t\tchauvan\n",
            "228\t\tcatru\t\thatxam\n",
            "229\t\thatxam\t\thatxam\n",
            "230\t\thatxam\t\thatxam\n",
            "231\t\tcheo\t\tcheo\n",
            "232\t\tcailuong\t\tcailuong\n",
            "233\t\tchauvan\t\tchauvan\n",
            "234\t\tchauvan\t\tchauvan\n",
            "235\t\tcatru\t\tcatru\n",
            "236\t\thatxam\t\thatxam\n",
            "237\t\thatxam\t\thatxam\n",
            "238\t\tchauvan\t\tchauvan\n",
            "239\t\thatxam\t\thatxam\n",
            "240\t\tcatru\t\tcatru\n",
            "241\t\tcheo\t\tcheo\n",
            "242\t\tcailuong\t\tcailuong\n",
            "243\t\tcailuong\t\tcailuong\n",
            "244\t\tchauvan\t\tchauvan\n",
            "245\t\tcailuong\t\tcailuong\n",
            "246\t\tchauvan\t\tchauvan\n",
            "247\t\tcheo\t\tcheo\n",
            "248\t\tcheo\t\tcheo\n",
            "249\t\tcheo\t\tcheo\n",
            "250\t\tcailuong\t\tcailuong\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define the checkpoint filepath\n",
        "# checkpoint_dir = '/content/drive/MyDrive/Music_Project/music_data/checkpoint/DenseNet121'\n",
        "# os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# # Create a ModelCheckpoint callback\n",
        "# checkpoint_filepath = os.path.join(checkpoint_dir, 'Densenet')\n",
        "# checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "#     filepath=checkpoint_filepath,\n",
        "#     save_weights_only=True,  # Save only the model weights\n",
        "#     monitor='val_loss',  # Monitor validation loss\n",
        "#     mode='min',  # Save the model when validation loss is minimized\n",
        "#     save_best_only=True  # Save only the best model\n",
        "# )\n",
        "\n",
        "# # Assuming you have already trained and evaluated your model\n",
        "# # model.fit(train_data, epochs=10, validation_data=val_data, callbacks=[checkpoint_callback])\n",
        "\n",
        "# # After training, save the entire model\n",
        "# model.save('/content/drive/MyDrive/Music_Project/music_data/checkpoint/DenseNet121/densenet121_model_10s.h5')\n",
        "\n",
        "# # Also, save only the weights of the model\n",
        "# model.save_weights('/content/drive/MyDrive/Music_Project/music_data/checkpoint/DenseNet121/densenet121_weights_10s.h5')\n"
      ],
      "metadata": {
        "id": "09IbVoOjqUOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Tải checkpoint đã lưu\n",
        "# checkpoint_path = \"/content/drive/MyDrive/Music_Project/music_data/checkpoint/DenseNet121/densenet121_weights.h5\"\n",
        "# model_path = r\"/content/drive/MyDrive/Music_Project/music_data/checkpoint/DenseNet121/densenet121_model.h5\"\n",
        "# model = tf.keras.models.load_model(model_path)\n",
        "# model.load_weights(checkpoint_path)\n",
        "\n",
        "# # Đánh giá mô hình sau khi tải lại checkpoint\n",
        "\n",
        "# predict = model.predict(x_test)\n",
        "\n",
        "\n",
        "# # Convert one-hot encoded predicted labels back to original labels\n",
        "# test_predictions_labels = label_encoder.inverse_transform(np.argmax(predict, axis=1))\n",
        "# # Convert one-hot encoded predicted labels back to original labels\n",
        "# test_predictions_labels_encoded = label_encoder.inverse_transform(np.argmax(predict, axis=1))\n",
        "\n",
        "\n",
        "# # Calculate AUC_ROC\n",
        "# auc_roc = AUC()\n",
        "# auc_roc.update_state(y_test_one_hot, predict)\n",
        "# print(\"AUC ROC:\", auc_roc.result().numpy())\n",
        "\n",
        "# # Calculate F1 Score\n",
        "# f1 = F1Score()\n",
        "# f1.update_state(y_test_one_hot, predict)\n",
        "# print(\"F1 Score:\", np.mean(f1.result().numpy()))\n",
        "\n",
        "# # Calculate Precision\n",
        "# pre = Precision()\n",
        "# pre.update_state(y_test_one_hot, predict)\n",
        "# print(\"Precision Score\", pre.result().numpy())\n",
        "\n",
        "# # Accuracy Score\n",
        "# acc = accuracy_score(y_test, test_predictions_labels)\n",
        "# print(\"Accuracy Score\", acc)\n",
        "\n",
        "# print(\"Recall Score:\", recall_score(y_test_encoded, np.argmax(predict, axis=1), average='macro'))"
      ],
      "metadata": {
        "id": "56uRJidyqWM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint_path = \"/content/drive/MyDrive/Music_Project/music_data/checkpoint/DenseNet121/densenet121_weights.h5\"\n",
        "# model.load_weights(checkpoint_path)"
      ],
      "metadata": {
        "id": "mE9nCyllsXix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Late Fusion CNN"
      ],
      "metadata": {
        "id": "o54YuVR6seSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "def compute_melgram(audio_path, new_shape=(256, 1296)):\n",
        "\n",
        "\n",
        "    # Mel-spectrogram parameters\n",
        "    SR = 12000\n",
        "    N_FFT = 2048\n",
        "    N_MELS = 256\n",
        "    HOP_LEN = 256\n",
        "    DURA = 27.64  # to make it 1296 frames\n",
        "\n",
        "    # Load audio file\n",
        "    src, sr = librosa.load(audio_path, sr=SR)\n",
        "\n",
        "    # Ensure the audio is of desired duration\n",
        "    n_sample = src.shape[0]\n",
        "    n_sample_fit = int(DURA * SR)\n",
        "    if n_sample < n_sample_fit:  # if too short\n",
        "        src = np.hstack((src, np.zeros((int(DURA * SR) - n_sample,))))\n",
        "    elif n_sample > n_sample_fit:  # if too long\n",
        "        src = src[(n_sample - n_sample_fit) // 2:(n_sample + n_sample_fit) // 2]\n",
        "    melgram = librosa.feature.melspectrogram(y=src, sr=SR, hop_length=HOP_LEN, n_fft=N_FFT, n_mels=N_MELS)\n",
        "\n",
        "    return melgram\n",
        "def compute_stft(audio_path,new_shape=(256, 1296)):\n",
        "\n",
        "\n",
        "    # STFT parameters\n",
        "    SR = 22115\n",
        "    N_FFT = 510\n",
        "    HOP_LEN = 512\n",
        "\n",
        "    # Load audio file\n",
        "    src, sr = librosa.load(audio_path, sr=SR)\n",
        "\n",
        "    # Compute STFT\n",
        "    stft = librosa.stft(src, n_fft=N_FFT, hop_length=HOP_LEN)\n",
        "\n",
        "    return stft\n",
        "\n",
        "def compute_mfcc(audio_path,new_shape=(256, 1296)):\n",
        "\n",
        "\n",
        "    # MFCC parameters\n",
        "    SR = 22115\n",
        "    N_MFCC = 256\n",
        "    N_FFT = 510\n",
        "    HOP_LEN = 512\n",
        "\n",
        "    # Load audio file\n",
        "    src, sr = librosa.load(audio_path, sr=SR)\n",
        "\n",
        "    # Compute MFCC\n",
        "    mfcc = librosa.feature.mfcc(y=src, sr=SR, n_mfcc=N_MFCC, n_fft=N_FFT, hop_length=HOP_LEN)\n",
        "    return mfcc\n",
        "\n",
        "\n",
        "def process_audio_files(audio_dir):\n",
        "    stft_data = []\n",
        "    mel_data = []\n",
        "    mfcc_data = []\n",
        "    labels = []\n",
        "\n",
        "    max_frames = 1296  # Set a maximum number of frames\n",
        "    n_freq_bins = 256  # Number of frequency bins in the Mel-spectrogram\n",
        "\n",
        "    for genre_folder in os.listdir(audio_dir):\n",
        "        genre_path = os.path.join(audio_dir, genre_folder)\n",
        "        if os.path.isdir(genre_path):\n",
        "            for filename in os.listdir(genre_path):\n",
        "                if filename.endswith('.wav'):\n",
        "                    file_path = os.path.join(genre_path, filename)\n",
        "                    stft = compute_stft(file_path)\n",
        "                    mel = compute_melgram(file_path)\n",
        "                    mfcc = compute_mfcc(file_path)\n",
        "\n",
        "                    # Upsample MFCCs\n",
        "                    mfcc_upsampled = upsample_mfcc(mfcc, n_freq_bins)\n",
        "\n",
        "                    # Pad or crop arrays to ensure consistent shape\n",
        "                    stft = pad_or_crop_array(stft, max_frames)\n",
        "                    mel = pad_or_crop_array(mel, max_frames)\n",
        "                    mfcc_upsampled = pad_or_crop_array(mfcc_upsampled, max_frames)\n",
        "\n",
        "                    stft_data.append(stft)\n",
        "                    mel_data.append(mel)\n",
        "                    mfcc_data.append(mfcc_upsampled)\n",
        "                    labels.append(genre_folder)\n",
        "\n",
        "    stft_data = np.array(stft_data)\n",
        "    mel_data = np.array(mel_data)\n",
        "    mfcc_data = np.array(mfcc_data)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return stft_data, mel_data, mfcc_data, labels\n",
        "\n",
        "# Function to upsample MFCCs\n",
        "def upsample_mfcc(mfcc_data, n_freq_bins):\n",
        "    n_mfcc, n_frames = mfcc_data.shape\n",
        "    mfcc_upsampled = np.zeros((n_freq_bins, n_frames))\n",
        "\n",
        "    # Compute interpolation factor for each MFCC coefficient\n",
        "    factor = n_freq_bins // n_mfcc\n",
        "\n",
        "    # Upsample each MFCC coefficient\n",
        "    for i in range(n_mfcc):\n",
        "        mfcc_upsampled[i*factor:(i+1)*factor, :] = mfcc_data[i]\n",
        "\n",
        "    return mfcc_upsampled\n",
        "\n",
        "\n",
        "def pad_or_crop_array(array, target_length):\n",
        "    if array.shape[1] < target_length:\n",
        "        # Pad array with zeros along the time axis\n",
        "        padding = target_length - array.shape[1]\n",
        "        array = np.pad(array, ((0, 0), (0, padding)), mode='constant')\n",
        "    elif array.shape[1] > target_length:\n",
        "        # Crop array along the time axis\n",
        "        array = array[:, :target_length]\n",
        "    return array\n",
        "\n",
        "audio_dir = r'/content/drive/MyDrive/Music_Project/music_data/VNTM3'\n",
        "stft_data, mel_data, mfcc_data, labels = process_audio_files(audio_dir)"
      ],
      "metadata": {
        "id": "oxBhwaxjm6EH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here you can continue with your splitting and reshaping steps as before\n",
        "stft_data = stft_data.reshape(stft_data.shape[0], stft_data.shape[1], stft_data.shape[2], 1)\n",
        "mel_data = mel_data.reshape(mel_data.shape[0], mel_data.shape[1], mel_data.shape[2], 1)\n",
        "mfcc_data = mfcc_data.reshape(mfcc_data.shape[0], mfcc_data.shape[1], mfcc_data.shape[2], 1)\n"
      ],
      "metadata": {
        "id": "RTGjo5tNm7KX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stft_data=stft_data.astype(\"float32\")\n",
        "mel_data =  mel_data.astype(\"float32\")\n",
        "mfcc_data =mfcc_data.astype(\"float32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtFAfMixm8Nv",
        "outputId": "94c3bc41-e12d-4d27-9f87-7acfa56ecaf1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-4f9efa9c68da>:1: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  stft_data=stft_data.astype(\"float32\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "stft_train, stft_test, mel_train, mel_test, mfcc_train, mfcc_test, labels_train, labels_test = train_test_split(\n",
        "    stft_data, mel_data, mfcc_data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split the training data into training and validation sets (80% train, 20% validation)\n",
        "stft_test, stft_val, mel_test, mel_val, mfcc_test, mfcc_val, labels_test, labels_val = train_test_split(\n",
        "    stft_test, mel_test, mfcc_test, labels_test, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "XFMYFDNNnE-P"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = r'/content/drive/MyDrive/Music_Project/music_data/checkpoint/LateFusion'\n",
        "\n",
        "saved_model_path = r'/content/drive/MyDrive/Music_Project/music_data/checkpoint/LateFusion'\n"
      ],
      "metadata": {
        "id": "azDMYtGsnHKm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout, Concatenate, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
        "\n",
        "def late_fusion(model,stft_input_shape, melgram_input_shape,mfcc_input_shape):\n",
        "    # Define Group1 Block\n",
        "    input_stft = Input(shape=stft_input_shape)\n",
        "    stft = Conv2D(20, (7, 7), strides=(2, 2), activation='relu', padding='same')(input_stft)\n",
        "    stft = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(stft)\n",
        "    stft = dropout_block(stft, units=42)\n",
        "    stft = transition_layer(stft, filters=42)\n",
        "    stft = dropout_block(stft, units=85)\n",
        "    stft = transition_layer(stft, filters=85)\n",
        "    stft = dropout_block(stft, units=170)\n",
        "    stft = transition_layer(stft, filters=170)\n",
        "    stft = dropout_block(stft, units=341)\n",
        "    stft = GlobalAveragePooling2D()(stft)  # Adding Global Average Pooling\n",
        "\n",
        "\n",
        "    # Define Group2 Block\n",
        "    input_melgram = Input(shape=melgram_input_shape)\n",
        "    melgram = Conv2D(20, (7, 7), strides=(2, 2), activation='relu', padding='same')(input_melgram)\n",
        "    melgram = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(melgram)\n",
        "    melgram = dropout_block(melgram, units=42)\n",
        "    melgram = transition_layer(melgram, filters=42)\n",
        "    melgram = dropout_block(melgram, units=85)\n",
        "    melgram = transition_layer(melgram, filters=85)\n",
        "    melgram = dropout_block(melgram, units=170)\n",
        "    melgram = transition_layer(melgram, filters=170)\n",
        "    melgram = dropout_block(melgram, units=341)\n",
        "    melgram = GlobalAveragePooling2D()(melgram)\n",
        "    # Define Group3 Block\n",
        "\n",
        "\n",
        "    input_mfcc = Input(shape=mfcc_input_shape)\n",
        "    mfcc = Conv2D(20, (7, 7), strides=(2, 2), activation='relu', padding='same')(input_mfcc)\n",
        "    mfcc = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(mfcc)\n",
        "    mfcc = dropout_block(mfcc, units=42)  # Using a function for dropout block\n",
        "    mfcc = transition_layer(mfcc, filters=42)\n",
        "    mfcc = dropout_block(mfcc, units=85)\n",
        "    mfcc = transition_layer(mfcc, filters=85)\n",
        "    mfcc = dropout_block(mfcc, units=170)\n",
        "    mfcc = transition_layer(mfcc, filters=170)\n",
        "    mfcc = dropout_block(mfcc, units=341)\n",
        "    mfcc = GlobalAveragePooling2D()(mfcc)  # Adding Global Average Pooling\n",
        "\n",
        "    # Concatenate outputs of all groups\n",
        "    concatenated_output = Concatenate()([ stft, melgram,mfcc])\n",
        "\n",
        "    # Global Average Pooling\n",
        "    # Fully Connected Layer\n",
        "    output = Dense(5, activation='softmax')(concatenated_output)\n",
        "\n",
        "    # Define the model\n",
        "    model = Model(inputs=[ input_stft, input_melgram,input_mfcc], outputs=output)\n",
        "    if not os.path.exists(checkpoint_filepath + '/latefusion'):\n",
        "        os.makedirs(checkpoint_filepath + '/latefusion')\n",
        "    checkpoint1= tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath= checkpoint_filepath + '/latefusion' + '/latefusion_{epoch:02d}_{val_accuracy:.4f}.weights.h5',\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True,\n",
        "    verbose=1\n",
        "    )\n",
        "\n",
        "    return model,checkpoint1\n",
        "\n",
        "def dropout_block(input_layer, units):\n",
        "    x = Dense(units, activation='relu')(input_layer)\n",
        "    x = Dropout(0.1)(x)\n",
        "    return x\n",
        "\n",
        "def transition_layer(input_layer, filters):\n",
        "    x = Conv2D(filters, (1, 1), activation='relu')(input_layer)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "3ivxaAydnH8u"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the late fusion model using provided input shapes\n",
        "mfcc_input_shape = (256, 1296, 1)  # Example shape, adjust according to your actual data\n",
        "stft_input_shape = (256, 1296, 1)  # Example shape, adjust according to your actual data\n",
        "melgram_input_shape = (256, 1296, 1)  # Example shape, adjust according to your actual data\n",
        "model1 = tf.keras.Sequential()\n",
        "model1,checkpoint1 = late_fusion(model1,stft_input_shape ,melgram_input_shape, mfcc_input_shape,)\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model1.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVWky3ROnJNG",
        "outputId": "44fb6ae5-3917-4503-a0b7-0359dac441e2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 1296, 1)]       0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 256, 1296, 1)]       0         []                            \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)        [(None, 256, 1296, 1)]       0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 128, 648, 20)         1000      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 128, 648, 20)         1000      ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 128, 648, 20)         1000      ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 63, 323, 20)          0         ['conv2d[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPoolin  (None, 63, 323, 20)          0         ['conv2d_4[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPoolin  (None, 63, 323, 20)          0         ['conv2d_8[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 63, 323, 42)          882       ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 63, 323, 42)          882       ['max_pooling2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 63, 323, 42)          882       ['max_pooling2d_8[0][0]']     \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 63, 323, 42)          0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 63, 323, 42)          0         ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 63, 323, 42)          0         ['dense_8[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 63, 323, 42)          1806      ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 63, 323, 42)          1806      ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 63, 323, 42)          1806      ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 31, 161, 42)          0         ['conv2d_1[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPoolin  (None, 31, 161, 42)          0         ['conv2d_5[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPoolin  (None, 31, 161, 42)          0         ['conv2d_9[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 31, 161, 85)          3655      ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 31, 161, 85)          3655      ['max_pooling2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, 31, 161, 85)          3655      ['max_pooling2d_9[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 31, 161, 85)          0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 31, 161, 85)          0         ['dense_5[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)         (None, 31, 161, 85)          0         ['dense_9[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 31, 161, 85)          7310      ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 31, 161, 85)          7310      ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 31, 161, 85)          7310      ['dropout_9[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 15, 80, 85)           0         ['conv2d_2[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPoolin  (None, 15, 80, 85)           0         ['conv2d_6[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooli  (None, 15, 80, 85)           0         ['conv2d_10[0][0]']           \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 15, 80, 170)          14620     ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 15, 80, 170)          14620     ['max_pooling2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 15, 80, 170)          14620     ['max_pooling2d_10[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 15, 80, 170)          0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 15, 80, 170)          0         ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)        (None, 15, 80, 170)          0         ['dense_10[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 15, 80, 170)          29070     ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 15, 80, 170)          29070     ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 15, 80, 170)          29070     ['dropout_10[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 7, 40, 170)           0         ['conv2d_3[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPoolin  (None, 7, 40, 170)           0         ['conv2d_7[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooli  (None, 7, 40, 170)           0         ['conv2d_11[0][0]']           \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 7, 40, 341)           58311     ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 7, 40, 341)           58311     ['max_pooling2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 7, 40, 341)           58311     ['max_pooling2d_11[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 7, 40, 341)           0         ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 7, 40, 341)           0         ['dense_7[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)        (None, 7, 40, 341)           0         ['dense_11[0][0]']            \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 341)                  0         ['dropout_3[0][0]']           \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 341)                  0         ['dropout_7[0][0]']           \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2  (None, 341)                  0         ['dropout_11[0][0]']          \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 1023)                 0         ['global_average_pooling2d[0][\n",
            "                                                                    0]',                          \n",
            "                                                                     'global_average_pooling2d_1[0\n",
            "                                                                    ][0]',                        \n",
            "                                                                     'global_average_pooling2d_2[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, 5)                    5120      ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 355082 (1.35 MB)\n",
            "Trainable params: 355082 (1.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "early = EarlyStopping(monitor='loss',\n",
        "    patience= 5,\n",
        "    verbose= 0,\n",
        "    mode='auto',\n",
        "    baseline= None,\n",
        "    restore_best_weights= True)\n"
      ],
      "metadata": {
        "id": "Xgx8-I8onOV-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "label_binarizer = LabelBinarizer()\n",
        "y_train_one_hot = label_binarizer.fit_transform(labels_train)\n",
        "y_val_one_hot = label_binarizer.transform(labels_val)\n",
        "y_eval_one_hot = label_binarizer.transform(labels_test)"
      ],
      "metadata": {
        "id": "phVNTy8anO82"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model1.fit([stft_train,  mel_train,mfcc_train],\n",
        "                     y_train_one_hot,\n",
        "                     batch_size=32,\n",
        "                     epochs=100,\n",
        "                     validation_data=([stft_val,mel_val,mfcc_val], y_val_one_hot),\n",
        "                     callbacks=[checkpoint1, early])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8RSjU_7nPoW",
        "outputId": "f013fa07-7900-434a-b7d2-afafdd61f473"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 1.3729 - accuracy: 0.4307\n",
            "Epoch 1: val_accuracy improved from -inf to 0.56800, saving model to /content/drive/MyDrive/Music_Project/music_data/checkpoint/LateFusion/latefusion/latefusion_01_0.5680.weights.h5\n",
            "63/63 [==============================] - 21s 160ms/step - loss: 1.3729 - accuracy: 0.4307 - val_loss: 1.1433 - val_accuracy: 0.5680\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 1.0088 - accuracy: 0.5788\n",
            "Epoch 2: val_accuracy improved from 0.56800 to 0.58000, saving model to /content/drive/MyDrive/Music_Project/music_data/checkpoint/LateFusion/latefusion/latefusion_02_0.5800.weights.h5\n",
            "63/63 [==============================] - 8s 127ms/step - loss: 1.0088 - accuracy: 0.5788 - val_loss: 0.9059 - val_accuracy: 0.5800\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.7053 - accuracy: 0.7394\n",
            "Epoch 3: val_accuracy improved from 0.58000 to 0.71200, saving model to /content/drive/MyDrive/Music_Project/music_data/checkpoint/LateFusion/latefusion/latefusion_03_0.7120.weights.h5\n",
            "63/63 [==============================] - 8s 126ms/step - loss: 0.7053 - accuracy: 0.7394 - val_loss: 0.7154 - val_accuracy: 0.7120\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.6239 - accuracy: 0.7699\n",
            "Epoch 4: val_accuracy improved from 0.71200 to 0.82000, saving model to /content/drive/MyDrive/Music_Project/music_data/checkpoint/LateFusion/latefusion/latefusion_04_0.8200.weights.h5\n",
            "63/63 [==============================] - 8s 127ms/step - loss: 0.6239 - accuracy: 0.7699 - val_loss: 0.5255 - val_accuracy: 0.8200\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.5184 - accuracy: 0.8094\n",
            "Epoch 5: val_accuracy did not improve from 0.82000\n",
            "63/63 [==============================] - 8s 124ms/step - loss: 0.5184 - accuracy: 0.8094 - val_loss: 0.5927 - val_accuracy: 0.7880\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.5056 - accuracy: 0.8194\n",
            "Epoch 6: val_accuracy did not improve from 0.82000\n",
            "63/63 [==============================] - 8s 122ms/step - loss: 0.5056 - accuracy: 0.8194 - val_loss: 0.6248 - val_accuracy: 0.7800\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.4510 - accuracy: 0.8389\n",
            "Epoch 7: val_accuracy improved from 0.82000 to 0.82800, saving model to /content/drive/MyDrive/Music_Project/music_data/checkpoint/LateFusion/latefusion/latefusion_07_0.8280.weights.h5\n",
            "63/63 [==============================] - 8s 127ms/step - loss: 0.4510 - accuracy: 0.8389 - val_loss: 0.5194 - val_accuracy: 0.8280\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.3696 - accuracy: 0.8669\n",
            "Epoch 8: val_accuracy improved from 0.82800 to 0.86800, saving model to /content/drive/MyDrive/Music_Project/music_data/checkpoint/LateFusion/latefusion/latefusion_08_0.8680.weights.h5\n",
            "63/63 [==============================] - 8s 127ms/step - loss: 0.3696 - accuracy: 0.8669 - val_loss: 0.3913 - val_accuracy: 0.8680\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.3225 - accuracy: 0.8834\n",
            "Epoch 9: val_accuracy did not improve from 0.86800\n",
            "63/63 [==============================] - 8s 123ms/step - loss: 0.3225 - accuracy: 0.8834 - val_loss: 0.4877 - val_accuracy: 0.8320\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.3275 - accuracy: 0.8854\n",
            "Epoch 10: val_accuracy improved from 0.86800 to 0.87200, saving model to /content/drive/MyDrive/Music_Project/music_data/checkpoint/LateFusion/latefusion/latefusion_10_0.8720.weights.h5\n",
            "63/63 [==============================] - 8s 129ms/step - loss: 0.3275 - accuracy: 0.8854 - val_loss: 0.4006 - val_accuracy: 0.8720\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2976 - accuracy: 0.8934\n",
            "Epoch 11: val_accuracy improved from 0.87200 to 0.91600, saving model to /content/drive/MyDrive/Music_Project/music_data/checkpoint/LateFusion/latefusion/latefusion_11_0.9160.weights.h5\n",
            "63/63 [==============================] - 8s 126ms/step - loss: 0.2976 - accuracy: 0.8934 - val_loss: 0.3014 - val_accuracy: 0.9160\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2879 - accuracy: 0.8984\n",
            "Epoch 12: val_accuracy did not improve from 0.91600\n",
            "63/63 [==============================] - 8s 122ms/step - loss: 0.2879 - accuracy: 0.8984 - val_loss: 0.3201 - val_accuracy: 0.8920\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2640 - accuracy: 0.9055\n",
            "Epoch 13: val_accuracy did not improve from 0.91600\n",
            "63/63 [==============================] - 8s 123ms/step - loss: 0.2640 - accuracy: 0.9055 - val_loss: 0.3035 - val_accuracy: 0.9040\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2142 - accuracy: 0.9240\n",
            "Epoch 14: val_accuracy did not improve from 0.91600\n",
            "63/63 [==============================] - 8s 121ms/step - loss: 0.2142 - accuracy: 0.9240 - val_loss: 0.2561 - val_accuracy: 0.9080\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2147 - accuracy: 0.9240\n",
            "Epoch 15: val_accuracy improved from 0.91600 to 0.94000, saving model to /content/drive/MyDrive/Music_Project/music_data/checkpoint/LateFusion/latefusion/latefusion_15_0.9400.weights.h5\n",
            "63/63 [==============================] - 8s 126ms/step - loss: 0.2147 - accuracy: 0.9240 - val_loss: 0.2064 - val_accuracy: 0.9400\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1750 - accuracy: 0.9400\n",
            "Epoch 16: val_accuracy improved from 0.94000 to 0.94400, saving model to /content/drive/MyDrive/Music_Project/music_data/checkpoint/LateFusion/latefusion/latefusion_16_0.9440.weights.h5\n",
            "63/63 [==============================] - 8s 126ms/step - loss: 0.1750 - accuracy: 0.9400 - val_loss: 0.1738 - val_accuracy: 0.9440\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.9475\n",
            "Epoch 17: val_accuracy did not improve from 0.94400\n",
            "63/63 [==============================] - 8s 122ms/step - loss: 0.1616 - accuracy: 0.9475 - val_loss: 0.4218 - val_accuracy: 0.8560\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1768 - accuracy: 0.9305\n",
            "Epoch 18: val_accuracy did not improve from 0.94400\n",
            "63/63 [==============================] - 8s 121ms/step - loss: 0.1768 - accuracy: 0.9305 - val_loss: 0.1912 - val_accuracy: 0.9320\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1329 - accuracy: 0.9540\n",
            "Epoch 19: val_accuracy did not improve from 0.94400\n",
            "63/63 [==============================] - 8s 120ms/step - loss: 0.1329 - accuracy: 0.9540 - val_loss: 0.2039 - val_accuracy: 0.9280\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1747 - accuracy: 0.9340\n",
            "Epoch 20: val_accuracy did not improve from 0.94400\n",
            "63/63 [==============================] - 8s 122ms/step - loss: 0.1747 - accuracy: 0.9340 - val_loss: 0.2082 - val_accuracy: 0.9240\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1981 - accuracy: 0.9300\n",
            "Epoch 21: val_accuracy did not improve from 0.94400\n",
            "63/63 [==============================] - 8s 123ms/step - loss: 0.1981 - accuracy: 0.9300 - val_loss: 0.2544 - val_accuracy: 0.9000\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1089 - accuracy: 0.9640\n",
            "Epoch 22: val_accuracy improved from 0.94400 to 0.95200, saving model to /content/drive/MyDrive/Music_Project/music_data/checkpoint/LateFusion/latefusion/latefusion_22_0.9520.weights.h5\n",
            "63/63 [==============================] - 8s 126ms/step - loss: 0.1089 - accuracy: 0.9640 - val_loss: 0.1545 - val_accuracy: 0.9520\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.9690\n",
            "Epoch 23: val_accuracy did not improve from 0.95200\n",
            "63/63 [==============================] - 8s 121ms/step - loss: 0.0808 - accuracy: 0.9690 - val_loss: 0.1608 - val_accuracy: 0.9440\n",
            "Epoch 24/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1884 - accuracy: 0.9360\n",
            "Epoch 24: val_accuracy did not improve from 0.95200\n",
            "63/63 [==============================] - 8s 123ms/step - loss: 0.1884 - accuracy: 0.9360 - val_loss: 0.2686 - val_accuracy: 0.9120\n",
            "Epoch 25/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9680\n",
            "Epoch 25: val_accuracy improved from 0.95200 to 0.96400, saving model to /content/drive/MyDrive/Music_Project/music_data/checkpoint/LateFusion/latefusion/latefusion_25_0.9640.weights.h5\n",
            "63/63 [==============================] - 8s 124ms/step - loss: 0.0948 - accuracy: 0.9680 - val_loss: 0.1333 - val_accuracy: 0.9640\n",
            "Epoch 26/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1392 - accuracy: 0.9515\n",
            "Epoch 26: val_accuracy did not improve from 0.96400\n",
            "63/63 [==============================] - 8s 122ms/step - loss: 0.1392 - accuracy: 0.9515 - val_loss: 0.1817 - val_accuracy: 0.9440\n",
            "Epoch 27/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1207 - accuracy: 0.9545\n",
            "Epoch 27: val_accuracy did not improve from 0.96400\n",
            "63/63 [==============================] - 8s 122ms/step - loss: 0.1207 - accuracy: 0.9545 - val_loss: 0.1730 - val_accuracy: 0.9560\n",
            "Epoch 28/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.9525\n",
            "Epoch 28: val_accuracy improved from 0.96400 to 0.96800, saving model to /content/drive/MyDrive/Music_Project/music_data/checkpoint/LateFusion/latefusion/latefusion_28_0.9680.weights.h5\n",
            "63/63 [==============================] - 8s 125ms/step - loss: 0.1274 - accuracy: 0.9525 - val_loss: 0.1393 - val_accuracy: 0.9680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from keras.metrics import AUC, F1Score, Precision, Accuracy\n",
        "\n",
        "# Evaluate the model\n",
        "predict = model1.predict([stft_test,mel_test,mfcc_test])\n",
        "predicted_labels = label_binarizer.inverse_transform(predict).tolist()\n",
        "\n",
        "# loss_eval, accuracy_eval = model.evaluate(X_eval, y_eval_one_hot)\n",
        "\n",
        "# print(f'Evaluation Loss: {loss_eval}, Evaluation Accuracy: {accuracy_eval}')\n",
        "# Calculate AUC ROC\n",
        "auc_roc = AUC()\n",
        "auc_roc.update_state(y_eval_one_hot, predict)\n",
        "print(\"AUC ROC:\", auc_roc.result().numpy())\n",
        "\n",
        "# Calculate F1 Score\n",
        "f1 = F1Score()\n",
        "f1.update_state(y_eval_one_hot, predict)\n",
        "print(\"F1 Score:\", np.mean(f1.result().numpy()))\n",
        "\n",
        "# Calculate Precision\n",
        "pre = Precision()\n",
        "pre.update_state(y_eval_one_hot, predict)\n",
        "print(\"Precision Score\", pre.result().numpy())\n",
        "\n",
        "# Accuracy Score\n",
        "acc = accuracy_score(labels_test, predicted_labels)\n",
        "print(\"Accuracy Score\", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeLj4oalnR0m",
        "outputId": "4f0da29a-1ede-498e-b325-a1e2fea41aa2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 40ms/step\n",
            "AUC ROC: 0.99575007\n",
            "F1 Score: 0.93935597\n",
            "Precision Score 0.93877554\n",
            "Accuracy Score 0.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(labels_test)):\n",
        "    print(labels_test[i], predicted_labels[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y6DgTm-nnTe",
        "outputId": "046430b3-e20b-4340-ba2e-b78cceb35104"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cailuong cailuong\n",
            "catru catru\n",
            "cailuong cailuong\n",
            "catru catru\n",
            "cailuong cailuong\n",
            "cheo cheo\n",
            "chauvan chauvan\n",
            "cheo cheo\n",
            "cailuong cailuong\n",
            "cheo cheo\n",
            "cheo cheo\n",
            "cailuong cailuong\n",
            "catru catru\n",
            "cailuong cailuong\n",
            "cailuong cailuong\n",
            "cailuong hatxam\n",
            "cailuong cailuong\n",
            "hatxam hatxam\n",
            "cailuong cailuong\n",
            "cailuong cailuong\n",
            "catru catru\n",
            "cailuong cailuong\n",
            "hatxam hatxam\n",
            "cailuong cailuong\n",
            "cailuong cailuong\n",
            "cheo cheo\n",
            "cailuong cailuong\n",
            "hatxam hatxam\n",
            "chauvan chauvan\n",
            "cailuong cailuong\n",
            "chauvan chauvan\n",
            "hatxam hatxam\n",
            "cailuong cailuong\n",
            "cheo cheo\n",
            "cailuong cailuong\n",
            "cheo cheo\n",
            "hatxam hatxam\n",
            "cheo cheo\n",
            "hatxam hatxam\n",
            "chauvan catru\n",
            "cailuong cailuong\n",
            "hatxam hatxam\n",
            "chauvan chauvan\n",
            "hatxam hatxam\n",
            "catru catru\n",
            "hatxam hatxam\n",
            "hatxam hatxam\n",
            "chauvan hatxam\n",
            "catru catru\n",
            "cailuong cailuong\n",
            "cailuong cailuong\n",
            "hatxam hatxam\n",
            "catru catru\n",
            "hatxam hatxam\n",
            "cheo cailuong\n",
            "catru catru\n",
            "cheo cheo\n",
            "chauvan catru\n",
            "cheo cheo\n",
            "catru catru\n",
            "catru catru\n",
            "cheo cheo\n",
            "catru catru\n",
            "catru catru\n",
            "chauvan chauvan\n",
            "cheo cheo\n",
            "cailuong cailuong\n",
            "cailuong cailuong\n",
            "catru catru\n",
            "catru catru\n",
            "cailuong cailuong\n",
            "cailuong cheo\n",
            "catru catru\n",
            "hatxam hatxam\n",
            "chauvan chauvan\n",
            "chauvan chauvan\n",
            "cailuong cailuong\n",
            "cheo cheo\n",
            "cheo cheo\n",
            "hatxam hatxam\n",
            "cheo cheo\n",
            "catru catru\n",
            "hatxam hatxam\n",
            "chauvan chauvan\n",
            "chauvan chauvan\n",
            "chauvan chauvan\n",
            "catru catru\n",
            "hatxam hatxam\n",
            "hatxam hatxam\n",
            "catru catru\n",
            "chauvan chauvan\n",
            "cailuong cailuong\n",
            "cailuong cailuong\n",
            "hatxam hatxam\n",
            "hatxam hatxam\n",
            "chauvan chauvan\n",
            "hatxam hatxam\n",
            "cheo cheo\n",
            "chauvan chauvan\n",
            "cailuong cailuong\n",
            "chauvan chauvan\n",
            "cailuong cailuong\n",
            "hatxam hatxam\n",
            "chauvan chauvan\n",
            "cheo cheo\n",
            "cailuong cailuong\n",
            "hatxam hatxam\n",
            "cailuong cailuong\n",
            "cheo cheo\n",
            "cheo cheo\n",
            "cheo cheo\n",
            "cailuong cailuong\n",
            "cailuong cailuong\n",
            "hatxam hatxam\n",
            "cailuong cailuong\n",
            "chauvan chauvan\n",
            "cheo cheo\n",
            "hatxam hatxam\n",
            "cailuong cailuong\n",
            "cailuong cailuong\n",
            "cheo cheo\n",
            "hatxam hatxam\n",
            "chauvan catru\n",
            "cailuong cailuong\n",
            "chauvan chauvan\n",
            "hatxam hatxam\n",
            "chauvan chauvan\n",
            "catru catru\n",
            "catru catru\n",
            "chauvan chauvan\n",
            "cheo cheo\n",
            "hatxam catru\n",
            "cheo cheo\n",
            "cheo cheo\n",
            "catru catru\n",
            "cailuong hatxam\n",
            "cheo cheo\n",
            "catru catru\n",
            "catru catru\n",
            "hatxam hatxam\n",
            "chauvan chauvan\n",
            "catru catru\n",
            "hatxam hatxam\n",
            "cailuong cailuong\n",
            "cailuong cailuong\n",
            "catru catru\n",
            "cailuong cailuong\n",
            "cheo cheo\n",
            "hatxam hatxam\n",
            "hatxam hatxam\n",
            "cheo cheo\n",
            "cheo cheo\n",
            "chauvan chauvan\n",
            "chauvan chauvan\n",
            "cheo cheo\n",
            "catru catru\n",
            "hatxam hatxam\n",
            "chauvan cheo\n",
            "cailuong cailuong\n",
            "cheo cheo\n",
            "catru catru\n",
            "hatxam hatxam\n",
            "cheo cheo\n",
            "cailuong cailuong\n",
            "hatxam hatxam\n",
            "cheo cheo\n",
            "chauvan chauvan\n",
            "chauvan chauvan\n",
            "hatxam hatxam\n",
            "catru catru\n",
            "cailuong cailuong\n",
            "cheo cheo\n",
            "catru catru\n",
            "catru catru\n",
            "chauvan chauvan\n",
            "hatxam hatxam\n",
            "cheo cheo\n",
            "hatxam hatxam\n",
            "chauvan chauvan\n",
            "cailuong cailuong\n",
            "hatxam hatxam\n",
            "cailuong cailuong\n",
            "hatxam hatxam\n",
            "hatxam hatxam\n",
            "catru catru\n",
            "hatxam hatxam\n",
            "cheo cheo\n",
            "cailuong hatxam\n",
            "hatxam hatxam\n",
            "cheo cheo\n",
            "cailuong cailuong\n",
            "catru catru\n",
            "chauvan chauvan\n",
            "catru catru\n",
            "catru catru\n",
            "hatxam hatxam\n",
            "cheo cheo\n",
            "cheo cheo\n",
            "cailuong cailuong\n",
            "cheo cheo\n",
            "chauvan chauvan\n",
            "catru catru\n",
            "catru catru\n",
            "catru catru\n",
            "catru catru\n",
            "hatxam hatxam\n",
            "chauvan catru\n",
            "catru catru\n",
            "cailuong cailuong\n",
            "cailuong cailuong\n",
            "hatxam hatxam\n",
            "hatxam hatxam\n",
            "chauvan chauvan\n",
            "hatxam hatxam\n",
            "hatxam hatxam\n",
            "cailuong cailuong\n",
            "cailuong cailuong\n",
            "chauvan chauvan\n",
            "catru catru\n",
            "hatxam hatxam\n",
            "chauvan chauvan\n",
            "cheo cheo\n",
            "hatxam hatxam\n",
            "chauvan chauvan\n",
            "hatxam hatxam\n",
            "cailuong cailuong\n",
            "chauvan hatxam\n",
            "cheo cheo\n",
            "cailuong cheo\n",
            "cheo cheo\n",
            "catru catru\n",
            "hatxam hatxam\n",
            "hatxam hatxam\n",
            "chauvan chauvan\n",
            "hatxam hatxam\n",
            "chauvan chauvan\n",
            "cailuong hatxam\n",
            "hatxam hatxam\n",
            "cheo cheo\n",
            "cailuong cailuong\n",
            "cailuong cailuong\n",
            "chauvan chauvan\n",
            "chauvan chauvan\n",
            "catru catru\n",
            "hatxam hatxam\n",
            "catru catru\n",
            "catru catru\n",
            "catru catru\n",
            "chauvan chauvan\n",
            "catru catru\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sq3P8yveyioL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}